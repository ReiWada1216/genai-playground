{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0849d3f",
   "metadata": {},
   "source": [
    "# ä¸–ç•Œãƒ¢ãƒ‡ãƒ«é“å ´(ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç·¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ff2d8",
   "metadata": {},
   "source": [
    "**VAE, VQ-VAE, Diffusionã®ç†è«–ã¨å®Ÿè£…, æ¯”è¼ƒ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6860ce6",
   "metadata": {},
   "source": [
    "## å…±é€šéƒ¨åˆ†ã®å®šç¾©ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª, ãƒ‡ãƒ¼ã‚¿, GPUï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7da9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1372e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----CUDA -> MPS(Mac) -> CPU ã®é †ã§è‡ªå‹•é¸æŠ\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")   # Apple Silicon (M1/M2) å‘ã‘\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----ç”»åƒã®å‰å‡¦ç†è¨­å®š-----\n",
    "#CelebAã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€[3, 218, 178]ãªã®ã§ã€128*128ã«å¤‰æ›´\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(178),         # ã¾ãšæ­£æ–¹å½¢(178x178)ã«ã‚»ãƒ³ã‚¿ãƒ¼ã‚¯ãƒ­ãƒƒãƒ—\n",
    "    transforms.Resize(128),              # 128*128ã¸ç¸®å°\n",
    "    transforms.ToTensor(),              # [0,1]\n",
    "])\n",
    "\n",
    "#----ã‚«ã‚¹ã‚¿ãƒ Datasetã®å®šç¾©----\n",
    "class CelebAImages(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        # jpgãŒç›´ä¸‹ã«ä¸¦ã‚“ã§ã„ã‚‹å‰æ\n",
    "        self.paths = sorted(glob.glob(os.path.join(root, '*.jpg')))\n",
    "        assert len(self.paths) > 0, f'No jpg found in: {root}'\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, 0   # ãƒ©ãƒ™ãƒ«ã¯ä½¿ã‚ãªã„ã®ã§ãƒ€ãƒŸãƒ¼\n",
    "\n",
    "#----ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹----\n",
    "root_dir = '/Users/wadarei/genai-playground/00_data/img_align_celeba/img_align_celeba'\n",
    "dataset = CelebAImages(root_dir, transform)\n",
    "\n",
    "#----8:2 ã§åˆ†å‰²----\n",
    "n = len(dataset); n_train = int(n*0.8)\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [n_train, n-n_train],\n",
    "                                                     generator=torch.Generator().manual_seed(42))\n",
    "#----DataLoaderåŒ–----\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª----\n",
    "# train_loaderã‹ã‚‰1ãƒãƒƒãƒå–å¾—\n",
    "images, _ = next(iter(train_loader))\n",
    "\n",
    "\n",
    "# ç”»åƒã‚’è¡¨ç¤º\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < images.shape[0]:\n",
    "        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ç”¨ã«æ•´å½¢\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Valid:\", len(val_data))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20e40e",
   "metadata": {},
   "source": [
    "## VAE(Variational Auto Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021aabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_log(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\" torch.log(0)ã«ã‚ˆã‚‹nanã‚’é˜²ãç›®çš„ \"\"\"\n",
    "    return torch.log(torch.clamp(x, min=1e-10))\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"VAEãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…\"\"\"\n",
    "    def __init__(self, z_dim:int) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        z_dim : int\n",
    "          æ½œåœ¨ç©ºé–“ã®æ¬¡å…ƒæ•°\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        #Encoder:  xã‚’å…¥åŠ›ã¨ã—ã¦ã€ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿mu, sigmaã‚’å‡ºåŠ›\n",
    "        #å…¥åŠ›ç”»åƒï¼š[B, 3, 128, 128]\n",
    "        self.conv_enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),  # -> [B, 64, 64, 64]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), # -> [B, 128, 32, 32]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), # -> [B, 256, 16, 16]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1), # -> [B, 512, 8, 8]\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \"\"\"\n",
    "        #å³å¯†ã«ã¯å®šç¾©ã—ãªãã¦ã„ã„ã‘ã©ã€ãã®å¾Œã®mu, sigmaã®linearã§å®šç¾©ã™ã‚‹ãŸã‚ã«å¿…è¦\n",
    "        \"\"\"\n",
    "        self.enc_flat = 512*8*8\n",
    "        self.enc_mu = nn.Linear(self.enc_flat, z_dim)\n",
    "        self.enc_var = nn.Linear(self.enc_flat, z_dim)\n",
    "\n",
    "        #Decoder: zã‚’å…¥åŠ›ã¨ã—ã¦ã€ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿mu, sigmaã‚’å‡ºåŠ›\n",
    "        self.fc_dec = nn.Linear(z_dim, self.enc_flat)\n",
    "        self.conv_dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1), # -> [B, 256, 16, 16]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # -> [B, 128, 32, 32]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64,  4, 2, 1),  # -> [B, 64, 64, 64]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64,  3,   4, 2, 1),  # -> [B, 3, 128, 128]\n",
    "            nn.Sigmoid()  # å‡ºåŠ›ã‚’ [0,1] ã«åã‚ã‚‹\n",
    "        )\n",
    "\n",
    "    def _encoder(self, x: torch.Tensor):\n",
    "      \"\"\"\n",
    "      ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€xã‹ã‚‰å¹³å‡ã¨åˆ†æ•£ã‚’å‡ºåŠ›ã™ã‚‹ã¨ã“ã‚ï¼ï¼\n",
    "      -------------\n",
    "      Parameters\n",
    "      x: torch.Tensor(b, c, h, w)\n",
    "      \"\"\"\n",
    "      x = self.conv_enc(x)\n",
    "      x = torch.flatten(x, start_dim=1) #ãƒãƒƒãƒã ã‘æ®‹ã™ã®ã§ã€start_dim=1\n",
    "      mean = self.enc_mu(x) #å¹³å‡\n",
    "      log_var = self.enc_var(x) #å¯¾æ•°åˆ†æ•£\n",
    "      return mean, log_var\n",
    "\n",
    "    def _sample_z(self, mean: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:\n",
    "      \"\"\"\n",
    "      VAEã§ã¯ã€Œæ½œåœ¨å¤‰æ•° ğ‘§ã€ã‚’ç¢ºç‡çš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹.\n",
    "      ã—ã‹ã—ã€ç¢ºç‡çš„ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ã¯å¾®åˆ†ãŒä¸å¯èƒ½ã«ãªã‚‹.\n",
    "      ãã®ãŸã‚ã€å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒˆãƒªãƒƒã‚¯ãŒå¿…è¦ï¼ï¼\n",
    "      -------------------\n",
    "      Parameters\n",
    "      mean: torch.Tensor(b, z_dim)\n",
    "        ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒå‡ºåŠ›ã™ã‚‹ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®å¹³å‡\n",
    "      log_var: torch.Tensor(b, z_dim)\n",
    "        ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒå‡ºåŠ›ã™ã‚‹ã‚¬ã‚¦ã‚¹åˆ†å¸ƒã®å¯¾æ•°åˆ†æ•£\n",
    "      \"\"\"\n",
    "      std = torch.exp(0.5 * log_var) #æ¨™æº–åå·®\n",
    "      eps = torch.randn_like(std) #stdã¨åŒã˜å½¢ã®ä¹±æ•°ã‚’ç”Ÿæˆï¼(å¹³å‡0, åˆ†æ•£1)\n",
    "      z = mean + std * eps\n",
    "      return z\n",
    "\n",
    "    def _decoder(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        VAEã®ãƒ‡ã‚³ãƒ¼ãƒ€éƒ¨åˆ†:zã‚’å—ã‘å–ã‚Šã€xã‚’å†æ§‹æˆã™ã‚‹\n",
    "        ----------\n",
    "        Parameters\n",
    "        z: torch.Tensor(b, z_dim)\n",
    "          æ½œåœ¨å¤‰æ•°\n",
    "        ----------\n",
    "        returns\n",
    "        x : torch.Tensor(b, c, h, w)\n",
    "        \"\"\"\n",
    "        x = self.fc_dec(z)\n",
    "        # x.viewã¯reshapeã¨åŒã˜åƒã\n",
    "        x = x.view(-1, 512, 8, 8)  #-1ã¯ã€PyTorchã«ã€Œã“ã®æ¬¡å…ƒã¯è‡ªåˆ†ã§è¨ˆç®—ã—ã¦ã€ã¨ä¼ãˆã‚‹ç‰¹åˆ¥ãªå€¤ã€‚\n",
    "        x = self.conv_dec(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        é †ä¼æ’­\n",
    "        ---------\n",
    "        Parameters\n",
    "        x : torch.Tensor ( b, c, h, w )\n",
    "              å…¥åŠ›ç”»åƒï¼\n",
    "        ---------\n",
    "        Returns\n",
    "        x : torch.Tensor ( b, c, h, w )\n",
    "              å†æ§‹æˆç”»åƒï¼\n",
    "        z : torch.Tensor ( b, z_dim )\n",
    "              æ½œåœ¨å¤‰æ•°ï¼\n",
    "        \"\"\"\n",
    "        mean, log_var = self._encoder(x)\n",
    "        z = self._sample_z(mean, log_var)\n",
    "        x = self._decoder(z)\n",
    "        return x, z\n",
    "\n",
    "    def loss(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        ç›®çš„é–¢æ•°ã®è¨ˆç®—\n",
    "        ----------\n",
    "        parameters\n",
    "        x: torch.Tensor(b, c, h, w)\n",
    "          å…¥åŠ›ç”»åƒ\n",
    "        ----------\n",
    "        returns\n",
    "        reconstruction: torch.Tensor(b, c, h, w)\n",
    "          å†æ§‹æˆç”»åƒ\n",
    "        KL: Torch.Tensor(, )\n",
    "          æ­£å‰‡åŒ–, ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰ã¨äº‹å‰åˆ†å¸ƒï¼ˆæ¨™æº–ã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼\n",
    "        \"\"\"\n",
    "        mean, log_var = self._encoder(x)\n",
    "        z = self._sample_z(mean, log_var)\n",
    "        x_hat = self._decoder(z)\n",
    "\n",
    "        #-----KLã®ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹, mean, std: (B, z_dim)\n",
    "        #torch.meanã¯batch_sizeã«é–¢ã™ã‚‹ã‚‚ã®\n",
    "        KL = -0.5 * torch.mean(torch.sum(1 + log_var - mean**2 - torch.exp(log_var), dim=1))\n",
    "\n",
    "        #----å†æ§‹æˆèª¤å·®(MSE): ã‚«ãƒ©ãƒ¼ç”»åƒã®å ´åˆã¯ã€ãƒã‚¤ãƒŠãƒªã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã§ã¯ãªãå¹³å‡äºŒä¹—èª¤å·®\n",
    "        reconstruction = F.mse_loss(x_hat, x, reduction='mean') #ãƒ”ã‚¯ã‚»ãƒ«ã”ã¨ã®èª¤å·®ã‚’å¹³å‡ã—ã¦ã„ã‚‹ #è² ã®å¯¾æ•°å°¤åº¦ã§ã¯ãªã„(å¹³å‡äºŒä¹—èª¤å·®ã ã‹ã‚‰)\n",
    "\n",
    "        #----ç›®çš„é–¢æ•°\n",
    "        loss = reconstruction + KL\n",
    "\n",
    "        return loss, reconstruction, KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194626b",
   "metadata": {},
   "source": [
    "## å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcba5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ ----\n",
    "z_dim = 100\n",
    "model = VAE(z_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # â† parameters() ã®ã‚¹ãƒšãƒ«ä¿®æ­£\n",
    "\n",
    "# ---- Trainer ----\n",
    "n_epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch [{epoch}/{n_epochs}]\", ncols=100)\n",
    "    total_loss, total_recon, total_kl = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, _ in pbar:\n",
    "        x = x.to(device)\n",
    "\n",
    "        # ---- Forward ----\n",
    "        loss, recon, kl = model.loss(x)\n",
    "\n",
    "        # ---- Backprop ----\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()           # backward\n",
    "        optimizer.step()           #optimizer\n",
    "\n",
    "        # ---- ãƒ­ã‚¹é›†è¨ˆ ----\n",
    "        total_loss += loss.item()\n",
    "        total_recon += recon.item()\n",
    "        total_kl += kl.item()\n",
    "\n",
    "        # ---- é€²æ—ãƒãƒ¼æ›´æ–° ----\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss.item():.3f}\",\n",
    "            \"Recon\": f\"{recon.item():.3f}\",\n",
    "            \"KL\": f\"{kl.item():.3f}\"\n",
    "        })\n",
    "\n",
    "    # ---- ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å¹³å‡ ----\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_recon = total_recon / len(train_loader)\n",
    "    avg_kl = total_kl / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Loss={avg_loss:.4f}, Recon={avg_recon:.4f}, KL={avg_kl:.4f}\")\n",
    "\n",
    "    # ---- å„ã‚¨ãƒãƒƒã‚¯å¾Œã®å†æ§‹æˆç”»åƒã‚’å¯è¦–åŒ– ----\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, _ = next(iter(train_loader))\n",
    "        x = x.to(device)\n",
    "        x_hat, _ = model(x)\n",
    "\n",
    "        def denorm(t): return (t.clamp(0, 1) + 1) / 2  \n",
    "        comparison = torch.cat([denorm(x[:8]), denorm(x_hat[:8])])\n",
    "        grid = torchvision.utils.make_grid(comparison, nrow=8)\n",
    "        plt.figure(figsize=(12, 3))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(f\"Epoch {epoch} Reconstruction\")\n",
    "        plt.show()\n",
    "\n",
    "    model.train()  # æ¬¡ã‚¨ãƒãƒƒã‚¯ã«æˆ»ã™\n",
    "\n",
    "# ---- å­¦ç¿’å¾Œã«ä¿å­˜ ----\n",
    "torch.save(model.state_dict(), \"vae_celeba.pth\")\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: vae_celeba.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genai-playground)",
   "language": "python",
   "name": "genai-playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
