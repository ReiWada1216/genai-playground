# scripts/train_vqvae.py
import argparse  # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import torch  # PyTorchã®ãƒ¡ã‚¤ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from torch.utils.data import DataLoader  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
import torchvision  # ç”»åƒå‡¦ç†ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import torch.nn.functional as F  # æ´»æ€§åŒ–é–¢æ•°ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys  # ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ã‚¹ã‚’æ“ä½œã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import os  # OSæ“ä½œã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '01_src'))  # srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 

try:  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
    from data.dataset import CelebAImages  # CelebAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹
    from models.model_vqvae import VQVAE  # VQVAEãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹
    from utils.logger import WandbLogger  # Weights & Biasesãƒ­ã‚¬ãƒ¼
    from utils.train_utils import get_device, save_checkpoint, load_checkpoint, get_scheduler  # å­¦ç¿’ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
except ImportError:  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ãŸå ´åˆ
    # çµ¶å¯¾ãƒ‘ã‚¹ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
    from data.dataset import CelebAImages
    from models.model_vqvae import VQVAE
    from utils.logger import WandbLogger
    from utils.train_utils import get_device, save_checkpoint, load_checkpoint, get_scheduler

import wandb  # Wandbãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tqdm import tqdm  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

def main(args):  # ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šå­¦ç¿’ã®å…¨ä½“çš„ãªæµã‚Œã‚’åˆ¶å¾¡
    # 1. ãƒ‡ãƒã‚¤ã‚¹è¨­å®š âš™ï¸
    device = get_device()  # GPU/CPUã‚’è‡ªå‹•é¸æŠã—ã¦ãƒ‡ãƒã‚¤ã‚¹ã‚’å–å¾—
    print(f"Using device: {device}")  # ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º

    # 2. ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ– (wandb) ğŸ“
    logger = WandbLogger(  # Weights & Biasesãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–
        project_name="Generated_AI_Project",  # wandbã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
        entity="lee137ritsss-",  # ã‚ãªãŸã®wandbãƒ¦ãƒ¼ã‚¶ãƒ¼å
        config={
            **vars(args),
            'model_type': 'VQVAE',
            'dataset': 'CelebA',
            'num_emb': args.num_emb,
            'emb_dim': args.emb_dim,
            'beta': args.beta
        }
    )

    # 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™ ğŸ“¦
    # CelebAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆtrainã¨downloadå¼•æ•°ã¯ä¸è¦ï¼‰
    try:  # transformã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
        from data.dataset import transform  # å‰å‡¦ç†ç”¨ã®transformã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    except ImportError:  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ãŸå ´åˆ
        from data.dataset import transform  # çµ¶å¯¾ãƒ‘ã‚¹ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    dataset = CelebAImages(root=args.data_path, transform=transform)  # CelebAImagesã‚¯ãƒ©ã‚¹ã«rootã¨transformã‚’æ¸¡ã™
    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ

    # å¯è¦–åŒ–ç”¨ã«å›ºå®šãƒãƒƒãƒã‚’æº–å‚™
    fixed_batch, _ = next(iter(dataloader))
    fixed_batch = fixed_batch.to(device)

    # 4. ãƒ¢ãƒ‡ãƒ«ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®åˆæœŸåŒ– ğŸ§ 
    model = VQVAE(num_emb=args.num_emb, emb_dim=args.emb_dim, beta=args.beta).to(device)  # VQVAEã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)  # Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’åˆæœŸåŒ–

    # 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ— 
    start_epoch = 0  # é–‹å§‹ã‚¨ãƒãƒƒã‚¯ã‚’å®šç¾©
    print("Training started...")  # å­¦ç¿’é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—å†…ã§ã€å„æå¤±ã‚’å€‹åˆ¥ã«è¿½è·¡
    for epoch in range(start_epoch, args.epochs):
        model.train()
        total_loss = 0
        total_recon_loss = 0  
        total_vq_loss = 0      

        pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{args.epochs}', leave=False)
        
        for batch_idx, (data, _) in enumerate(pbar):
            data = data.to(device)
            
            # VQVAEã®é †ä¼æ’­
            reconstruction, vq_loss, _ = model(data)

            # æå¤±ã®è¨ˆç®—ï¼ˆVQVAEãƒ¢ãƒ‡ãƒ«ã®lossãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼‰
            reconstruction_loss = F.mse_loss(reconstruction, data)
            total_loss = reconstruction_loss + vq_loss

            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()

            # å„æå¤±ã‚’ç´¯ç©
            total_loss += total_loss.item()
            total_recon_loss += reconstruction_loss.item()  
            total_vq_loss += vq_loss.item()                  
            
            pbar.set_postfix({
                'Loss': f'{total_loss.item():.4f}',
                'Recon': f'{reconstruction_loss.item():.4f}',
                'VQ': f'{vq_loss.item():.4f}'
            })
            
            # Wandbã«ãƒãƒƒãƒæ¯ã®æå¤±ã‚’ãƒ­ã‚°
            if batch_idx % args.log_interval == 0:
                global_step = epoch * len(dataloader) + batch_idx
                logger.log({
                    'train_loss': total_loss.item(),
                    'reconstruction_loss': reconstruction_loss.item(),
                    'vq_loss': vq_loss.item(),
                    'beta': args.beta
                }, step=global_step)
        
        # ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚ã®å¹³å‡æå¤±ã‚’ãƒ­ã‚°
        avg_loss = total_loss / len(dataloader)  # ç·æå¤±
        avg_recon_loss = total_recon_loss / len(dataloader)  # å†æ§‹æˆèª¤å·®
        avg_vq_loss = total_vq_loss / len(dataloader)        # VQæå¤±
        
        #ã‚¨ãƒãƒƒã‚¯ã®æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã§ãƒ­ã‚°ã‚’è¨˜éŒ²
        epoch_step = (epoch + 1) * len(dataloader)
        print(f"====> Epoch: {epoch+1} Average loss: {avg_loss:.4f}")
        logger.log({
            'epoch_avg_loss': avg_loss,
            'epoch_avg_reconstruction_loss': avg_recon_loss,
            'epoch_avg_vq_loss': avg_vq_loss
        }, step=epoch_step)

        # 7. ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ ğŸ’¾
        if (epoch + 1) % args.save_interval == 0:  # æŒ‡å®šã•ã‚ŒãŸé–“éš”ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜
            save_checkpoint(  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜é–¢æ•°ã‚’å‘¼ã³å‡ºã—
                model=model,  # å­¦ç¿’ä¸­ã®ãƒ¢ãƒ‡ãƒ«
                optimizer=optimizer,  # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹
                epoch=epoch,  # ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯æ•°
                checkpoint_dir=args.checkpoint_dir,  # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                model_name=f"vqvae_epoch_{epoch}.pth"  # ãƒ•ã‚¡ã‚¤ãƒ«å
            )

        # ç”»åƒç”Ÿæˆã®å¯è¦–åŒ–
        if (epoch + 1) % args.save_interval == 0:  # 1ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å®Ÿè¡Œ
            model.eval()
            with torch.no_grad():
                #1ã€€å†æ§‹æˆç”»åƒ
                reconstructed_images, _, _ = model(fixed_batch)

                #2ã€€ç”Ÿæˆç”»åƒï¼ˆVQVAEã§ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ç”Ÿæˆï¼‰
                # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ
                batch_size = fixed_batch.size(0)
                random_indices = torch.randint(0, args.num_emb, (batch_size * 4 * 4,)).to(device)  # 4x4ã®ç©ºé–“ã‚µã‚¤ã‚º
                random_indices = random_indices.view(batch_size, 4, 4)
                
                # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã‹ã‚‰å¯¾å¿œã™ã‚‹åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
                random_embeddings = model.vq_layer.embedding(random_indices.flatten())
                random_embeddings = random_embeddings.view(batch_size, args.emb_dim, 4, 4)
                
                # ãƒ‡ã‚³ãƒ¼ãƒ€ã§ç”»åƒã‚’ç”Ÿæˆ
                generated_images = model.decode(random_embeddings)

                #ã‚°ãƒªãƒƒãƒ‰ã®ä½œæˆ
                original_grid = torchvision.utils.make_grid(fixed_batch.cpu())
                reconstructed_grid = torchvision.utils.make_grid(reconstructed_images.cpu().clamp(0, 1))
                generated_grid = torchvision.utils.make_grid(generated_images.cpu().clamp(0, 1))
                
                # è¾æ›¸å½¢å¼ã§ä¸€åº¦ã«ãƒ­ã‚°
                logger.log({
                    "Originals": wandb.Image(original_grid),
                    "Reconstructions": wandb.Image(reconstructed_grid),
                    "Generated": wandb.Image(generated_grid)
                }, step=epoch_step)
            model.train()

    logger.finish()  # wandbã®ãƒ­ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†
    print("Training finished.")  # å­¦ç¿’å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸


if __name__ == '__main__':  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿å®Ÿè¡Œ
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰å­¦ç¿’è¨­å®šã‚’å—ã‘å–ã‚‹ãŸã‚ã®ãƒ‘ãƒ¼ã‚µãƒ¼
    parser = argparse.ArgumentParser(description="Train VQVAE Model")  # å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ
    parser.add_argument('--data_path', type=str, default='./data', help='path to dataset')  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate')  # å­¦ç¿’ç‡
    parser.add_argument('--batch_size', type=int, default=64, help='batch size')  # ãƒãƒƒãƒã‚µã‚¤ã‚º
    parser.add_argument('--epochs', type=int, default=50, help='number of epochs')  # ã‚¨ãƒãƒƒã‚¯æ•°
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='directory to save checkpoints')  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    parser.add_argument('--log_interval', type=int, default=100, help='how many batches to wait before logging status')  # ãƒ­ã‚°å‡ºåŠ›é–“éš”
    parser.add_argument('--save_interval', type=int, default=5, help='how many epochs to wait before saving model')  # ãƒ¢ãƒ‡ãƒ«ä¿å­˜é–“éš”
    
    # VQVAEç‰¹æœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--num_emb', type=int, default=512, help='number of embeddings in codebook')  # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒƒã‚¯ã®ã‚µã‚¤ã‚º
    parser.add_argument('--emb_dim', type=int, default=512, help='dimension of embeddings')  # åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒæ•°
    parser.add_argument('--beta', type=float, default=0.25, help='commitment loss weight')  # ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒ³ãƒˆæå¤±ã®é‡ã¿
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–¢é€£
    parser.add_argument('--resume_checkpoint', type=str, default=None, help='path to checkpoint to resume training from')  # å­¦ç¿’å†é–‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
    
    args = parser.parse_args()  # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ
    main(args)  # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ
